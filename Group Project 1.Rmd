--
title: 'Group Project #1'
author: "Bianca Brusco, Clare Clingain, Kaushik Mohan, & Frankie Wunschel"
date: "April 10, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
require(lme4)
require(lattice)
require(lmerTest)
classroom <- read.csv("data/classroom.csv")
```

#Part 1

##Create 1st grade variable
```{r}
classroom <- classroom %>% mutate(Math1st = mathkind + mathgain)
```

##UMM Model

```{r UMM}
#UMM model
model1 <- lmer(Math1st~(1|schoolid/classid),data=classroom)
summary(model1)
#the ICC
#class
85.46/(1146.8+280.68+85.46)
#school
280.68/(1146.8+280.68+85.46)
```

$Math1st_{ijk} = \beta_{0ijk} + \zeta_{k} + \eta_{jk} + \epsilon_{ijk}$
where $\zeta_{k} \sim N(0, \sigma_\zeta^2), \eta_{jk} \sim N(0, \sigma_\eta^2),$ and $\epsilon_{ijk} \sim N(0, \sigma_\epsilon^2)$, all independent of each other

##Add all school-level predictors

```{r school-level predictors}
model2 <- lmer(Math1st~housepov+(1|schoolid/classid),data=classroom)
summary(model2)
anova(model1, model2, refit = F) #is sig
```

Change in $\sigma_\zeta^2$: decreased to 250.93;  
$\sigma_\eta^2$= 82.36;  $\sigma_\epsilon^2$ = 1146.95

The anova test comparing model 1 to model 2 has a p-value : 3.39e-05, so we reject the null hypothesis at our $\alpha = 0.05$ and conclude that it makes sense to include the school level predictor, housepov. 

##Add all classroom-level predictors

```{r classroom-level predictors}
model3 <- lmer(Math1st~housepov+mathknow+yearstea+mathprep+(1|schoolid/classid),data=classroom)
summary(model3)


## CHECK...?


## creating reducted dataset taking away missing data
classroom_red = na.omit(classroom)
model2_red <- lmer(Math1st~housepov+(1|schoolid/classid),data=classroom_red)
model3_red <- lmer(Math1st~housepov+mathknow+yearstea+mathprep+(1|schoolid/classid),data=classroom_red)

anova(model2_red, model3_red, refit = F)
```

Change in $\sigma_\epsilon^2$ and $\sigma_\eta^2$: $\sigma_\epsilon^2$ decreased to 1136.43, $\sigma_\eta^2$ increased to 94.36; $\sigma_\zeta^2$ = 223.31

Why is epsilon reduced but not eta: explaining what's happening at student level but not classroom level. Moreover, adding class level predictors makes it so that more of the overall variation is explained by "structured" variation rather than by unstructured ($\epsilon$)
May increase because of sample decrease (missing data) --

The anova test comparing model 2 to model 3 has a p-value 0.08, so we fail to reject the null hypothesis at our $\alpha = 0.05$ and conclude that ??it does not make sense to include classsroom level predictors.???



##Add all student-level predictors

```{r student-level predictors}
#Add all student-level predictors
model4 <- lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1|schoolid/classid),data=classroom)
summary(model4)

## to test it with model 2 since anova for mod 3 not sig

model4_red <- lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1|schoolid/classid),data=classroom_red)

anova(model2_red, model4_red, refit = F)
anova(model3, model4, refit = F) #is sig
```

Change in zeta eta epsilon; $\sigma_\epsilon^2$ decreased to 1064.95, $\sigma_\eta^2$  decreased to 93.89, $\sigma_\zeta^2$ decreased to 169.45
School level may drop because students are similar in one school but different across schools

$\hat{math1st_{ijk}} = \beta_{0ijk} + \zeta_{k} + \eta_{jk} + \epsilon_{ijk} + \beta_1*Housepov_k +\beta_2*Mathknow_{jk} + \beta_3*YearsTea_{jk} + \beta_4*Mathprep_{jk} + \beta_5*sex_{ijk} + \beta_6*minority_{ijk} + \beta_7*ses_{ijk}$

The anova test comparing model 3 to model 4 has a p-value < 2.2e-16, so we reject the null hypothesis and conclude that it makes sense to include student level predictors. Moreover, the Chi-Sq test comparing model 2 to model 4 has a p-value < 2.2e-16, so we conclude that the model with student level predictors (as a block) improves compared to the model with only school-level predictors. 


##Random Slope for Teacher-level predictor varying at school-level

```{r random slope teachers}
#ONE BY ONE
#mathknow
rst.1 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+mathknow||schoolid)+(1|classid),data=classroom)
summary(rst.1)
#yearstea
rst.2 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+yearstea||schoolid)+(1|classid),data=classroom)
summary(rst.2)
#mathprep
rst.3 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+mathprep||schoolid)+(1|classid),data=classroom)
summary(rst.3)
```

Why housepov bad idea?

##Allowing correlations with random intercepts

```{r correlation with random intercepts}
#ONE BY ONE
#mathknow
rstc.1 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+mathknow|schoolid)+(1|classid),data=classroom)
summary(rstc.1)
#yearstea
rstc.2 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+yearstea|schoolid)+(1|classid),data=classroom)
summary(rstc.2)
#mathprep
rstc.3 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+mathprep|schoolid)+(1|classid),data=classroom)
summary(rstc.3)
```

anything unusual? Some of the correlations are exactly -1 between the random slope and the random intercept. 
why might this have occurred? (hint: what did you add to the model?)

##Random slopes for student-level predictors varying at classroom level

```{r random slope student-level}
#ONE BY ONE
#sex
rss.1 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+sex||classid)+(1|schoolid),data=classroom)
summary(rss.1)
#minority
rss.2 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+minority||classid)+(1|schoolid),data=classroom)
summary(rss.2)
#SES
rss.3 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+ses||classid)+(1|schoolid),data=classroom)
summary(rss.3)
```

why is this a bad idea to include a classroom-level variable with random slopes at classroom-level? Might not explain much variance.

##Allowing for correlations with random intercepts

```{r correlations}
#ONE BY ONE
#sex
rssc.1 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+sex|classid)+(1|schoolid),data=classroom)
summary(rssc.1)
#minority
rssc.2 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+minority|classid)+(1|schoolid),data=classroom)
summary(rssc.2)
#SES
rssc.3 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+ses|classid)+(1|schoolid),data=classroom)
summary(rssc.3)
```

##Random slopes for student-level predictors varying at school level

```{r random slopes student-level}
#ONE BY ONE
#sex
rss.4 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+sex||schoolid)+(1|classid),data=classroom)
summary(rss.4)
#minority
rss.5 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+minority||schoolid)+(1|classid),data=classroom)
summary(rss.5)
#SES
summary(rss.6)
```

##Allowing for correlations with random intercepts

```{r correlations student-school}
#ONE BY ONE
#sex
rssc.4 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+sex|schoolid)+(1|classid),data=classroom)
summary(rssc.4)
#minority
rssc.5 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+minority|schoolid)+(1|classid),data=classroom)
summary(rssc.5)
anova(model4, rssc.5) #sig
#SES
rssc.6 <-lmer(Math1st~housepov+mathknow+yearstea+mathprep+sex+minority+ses+(1+ses|schoolid)+(1|classid),data=classroom)
summary(rssc.6)
anova(model4, rssc.6)
```

Report unusual changes in variance

##Complex model better?

```{r}
#Take two predictors that had sig random slopes and add to model, test for need of one conditional on the other
#minority is sig
```

Is the more complex model justified?
Write the equation.
